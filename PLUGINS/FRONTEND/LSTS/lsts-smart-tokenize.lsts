
let lsts-tokenize-string(file-path: CString, text: CString): List<Token> = (
   lsts-tokenize-string( intern(file-path), intern(text) );
);

let lsts-tokenize-string(file-path: String, text: String): List<Token> = (
   smart-token-path-index = smart-token-path-index.bind( text.data as U64, file-path );

   let push-newline = 0;
   let tokens = [] : List<String>;
   while non-zero(text) {match text {
      "\s".. rest => text = rest;
      "\t".. rest => text = rest;
      "\n".. rest => (
         if push-newline {
            push-newline = 0;
            tokens = cons("\n", tokens);
         };
         text = rest;
      );

      "__".. rest => (tokens = cons(text[:"__".length], tokens); text = rest;);
      "**".. rest => (tokens = cons(text[:"**".length], tokens); text = rest;);
      "\\".. rest => (tokens = cons(text[:"\\".length], tokens); text = rest;);
      "~=".. rest => (tokens = cons(text[:"~=".length], tokens); text = rest;);
      "+=".. rest => (tokens = cons(text[:"+=".length], tokens); text = rest;);
      "-=".. rest => (tokens = cons(text[:"-=".length], tokens); text = rest;);
      "*=".. rest => (tokens = cons(text[:"*=".length], tokens); text = rest;);
      "/=".. rest => (tokens = cons(text[:"/=".length], tokens); text = rest;);
      "%=".. rest => (tokens = cons(text[:"%=".length], tokens); text = rest;);
      "&=".. rest => (tokens = cons(text[:"&=".length], tokens); text = rest;);
      "|=".. rest => (tokens = cons(text[:"|=".length], tokens); text = rest;);
      "<:".. rest => (tokens = cons(text[:"<:".length], tokens); text = rest;);
      "<=".. rest => (tokens = cons(text[:"<=".length], tokens); text = rest;);
      ">=".. rest => (tokens = cons(text[:">=".length], tokens); text = rest;);
      "==".. rest => (tokens = cons(text[:"==".length], tokens); text = rest;);
      "!=".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "&&".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "||".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "<".. rest => (tokens = cons(text[:"<".length], tokens); text = rest;);
      ">".. rest => (tokens = cons(text[:">".length], tokens); text = rest;);
      "{".. rest => (tokens = cons(text[:"{".length], tokens); text = rest;);
      "}".. rest => (tokens = cons(text[:"}".length], tokens); text = rest;);
      "[".. rest => (tokens = cons(text[:"[".length], tokens); text = rest;);
      "]".. rest => (tokens = cons(text[:"]".length], tokens); text = rest;);
      "(".. rest => (tokens = cons(text[:"(".length], tokens); text = rest;);
      ")".. rest => (tokens = cons(text[:")".length], tokens); text = rest;);
      ":".. rest => (tokens = cons(text[:":".length], tokens); text = rest;);
      ";".. rest => (tokens = cons(text[:";".length], tokens); text = rest;);
      ",".. rest => (tokens = cons(text[:",".length], tokens); text = rest;);
      "?".. rest => (tokens = cons(text[:"?".length], tokens); text = rest;);
      "~".. rest => (tokens = cons(text[:"~".length], tokens); text = rest;);
      "@".. rest => (tokens = cons(text[:"@".length], tokens); text = rest;);
      "+".. rest => (tokens = cons(text[:"+".length], tokens); text = rest;);
      "*".. rest => (tokens = cons(text[:"*".length], tokens); text = rest;);
      "/".. rest => (tokens = cons(text[:"/".length], tokens); text = rest;);
      "%".. rest => (tokens = cons(text[:"%".length], tokens); text = rest;);
      "&".. rest => (tokens = cons(text[:"&".length], tokens); text = rest;);
      "|".. rest => (tokens = cons(text[:"|".length], tokens); text = rest;);
      "!".. rest => (tokens = cons(text[:"!".length], tokens); text = rest;);
      "=".. rest => (tokens = cons(text[:"=".length], tokens); text = rest;);
      "^".. rest => (tokens = cons(text[:"^".length], tokens); text = rest;);
      ".".. rest => (tokens = cons(text[:".".length], tokens); text = rest;);

      (lin=r/^'[a-z]{1,3}/).. rest => (
         tokens = cons(text[:lin.length], tokens); text = rest;
      );

      # for docs
      "'".. rest => (tokens = cons(text[:"'".length], tokens); text = rest;);
      "##".. rest => (
         tokens = cons("##", tokens);
         text = rest;
         push-newline = 1;
      );

      (lit=r/^[r]?[cl]?["]([^"\\]|([\\].))*["]/).. rest => (
         tokens = cons(text[:lit.length], tokens); text = rest;
      );

      (rgx=r/^r[\/]([^\/]|([\\].))*[\/]/).. rest => (
         tokens = cons(text[:rgx.length], tokens); text = rest;
      );

      (id=r/^[$]["]([^"\\]|([\\].))*["]/).. rest => (
         tokens = cons(text[:id.length], tokens); text = rest;
      );

      "$".. rest => (tokens = cons(text[:"$".length], tokens); text = rest;);

      (id=r/^[a-zA-Z0-9_-]+/).. rest => (
         tokens = cons(text[:id.length], tokens); text = rest;
      );

      (comment=r/^#[^\n]*[\n]/).. rest => (
         text = rest;
      );

      #rest => fail("Unexpected Character during LSTS Tokenization: "
      #             "'\{rest[0_u64]}' "
      #             "in File \{rest.file-name-of-token}, "
      #             "Line \{rest.line-of-token}, "
      #             "Column \{rest.column-of-token}.");
      rest => ( fail("Unrecognized Token in File \{file-path}: \{clone-rope(rest[0_u64])}"); );
   }; };

   let internal-tokens = [] : List<Token>;
   for t in tokens {
      internal-tokens = cons( mk-lsts-token(t), internal-tokens );
   };

   internal-tokens;
);

